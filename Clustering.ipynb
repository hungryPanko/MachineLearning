{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7u0U9CbNCwbD",
    "outputId": "57eb34a3-d42e-4c35-f33d-d247e0f19a46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: munkres in /Users/Hanna/opt/anaconda3/envs/myenv_python3/lib/python3.7/site-packages (1.1.4)\r\n"
     ]
    }
   ],
   "source": [
    "# always import\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# numpy & scipy\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import pairwise_distances_argmin, pairwise_distances\n",
    "from sklearn import neighbors\n",
    "\n",
    "# Hungarian algorithm\n",
    "!pip install munkres\n",
    "from munkres import Munkres\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# visuals\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "from sklearn.manifold import Isomap, TSNE\n",
    "\n",
    "# maybe\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6ZyaFxjSC3P4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import homogeneity_score, completeness_score, \\\n",
    "        v_measure_score, adjusted_rand_score, adjusted_mutual_info_score \n",
    "\n",
    "def evaluation_metrics(true, pred):\n",
    "    return homogeneity_score(true, pred), completeness_score(true, pred),  \\\n",
    "        v_measure_score(true, pred), adjusted_rand_score(true, pred), adjusted_mutual_info_score(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Cmo1LClt2kUe"
   },
   "outputs": [],
   "source": [
    "# load MNIST data \n",
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, data_home='mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43VAz4yF2kXG",
    "outputId": "b38d4c43-9617-4d65-b378-202e8a6c4ed3"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# a randomly sampled smaller subset \n",
    "from sklearn.utils import resample\n",
    "X.insert(X.shape[1], 'y', y) # Add y to last column of X\n",
    "X = resample(X, n_samples=30000) # Reduce sample size to 7000 (10%)\n",
    "print(X.shape, y.shape)\n",
    "#Detach y from X again. \n",
    "y = X['y']\n",
    "X = X.drop(columns=['y'])\n",
    "print(X.shape, y.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jVQe7wHb2kZ1"
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "y = np.asarray(list(map(int, y)))\n",
    "X = np.asarray(X.astype(float))\n",
    "X = scale(X)\n",
    "n_digits = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jJHW3wnC2kcG"
   },
   "outputs": [],
   "source": [
    "# TODO: Kmeans\n",
    "from scipy.spatial.distance import cdist \n",
    "\n",
    "#Function to implement steps given in previous section\n",
    "#X: training data, n_digits:10(for MNIST, it is 10), init: init centroid method \"PrincipleEigenvectors or ForgySeedMethod \")\n",
    "def kmeans(x, k, max_iterations=300, e=1e-4, init=\"ForgySeedMethod\"):\n",
    "    # Step 1: Initialization of K: Randomly choosing centroids from X (the Forgy seed method)\n",
    "    if init == \"ForgySeedMethod\": \n",
    "        idx = np.random.choice(len(x), k, replace=False)\n",
    "        centroids = x[idx, :]\n",
    "    elif init == \"PrincipleEigenvectors\":\n",
    "        pca = PCA()\n",
    "        pca.fit_transform(x)\n",
    "        centroids = pca.components_[:k,:] # 10 principle eigenvectors\n",
    "      \n",
    "    # Step 2 : Assign each data point xi to the closet centroid\n",
    "    distances = cdist(x, centroids ,'euclidean') # distance between X and centeroids #Cluster Labe: 0-9\n",
    "    points = np.array([np.argmin(i) for i in distances]) # Centroid with the minimum Distance\n",
    "     \n",
    "    # Step 3: update each cluster centroid Cj as the mean of the data points assigned to cluster-j, i.e.\n",
    "    iter = 0\n",
    "    objective = 1e+10\n",
    "    e = 1\n",
    "    while (iter <= max_iterations) and (e > 1e-4): #if the number of iterations reaches a maximum value T. and (e > 1e-4)\n",
    "        iter+=1\n",
    "        centroids = []\n",
    "        # Find the new mean\n",
    "        for idx in range(k):\n",
    "            mean_cent = x[points==idx].mean(axis=0) #Updating Centroids by taking mean of Cluster it belongs to\n",
    "            centroids.append(mean_cent)\n",
    "        \n",
    "        #Objective function\n",
    "        objective_before = objective\n",
    "        objective = np.square(cdist(x, centroids ,'euclidean')).sum() #Distance^2 from x to centeroid that x is assigned. \n",
    "        e = abs(objective_before - objective)\n",
    "  \n",
    "        centroids = np.vstack(centroids) #Updated Centroids \n",
    "        distances = cdist(x, centroids ,'euclidean')\n",
    "        points = np.array([np.argmin(i) for i in distances])\n",
    "         \n",
    "    return points, objective, centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wxC-z6lO2kg3",
    "outputId": "d4e3af30-226b-4f27-8b06-03ebb8631ef1"
   },
   "outputs": [],
   "source": [
    "#Problem 2(a)-i. [9 points] Use the top-K principle eigenvectors of X achieved by PCA as the the K initial cluster \n",
    "#centroids in Step 1, and run your K-means implementation once on the original MNIST dataset X with the 784 raw pixel \n",
    "#features. Report the five evaluation metrics.\n",
    "print(\"[Problem 2(a)-i]\")\n",
    "print(\". Initial cluster: K principle eigenvctors\")\n",
    "print(\". Data: original MNIST dataset X with the 784 raw pixel\")\n",
    "label1, objective, centroids = kmeans(X, n_digits, init=\"PrincipleEigenvectors\")\n",
    "print(\". Report the five evaluation metrics: \")\n",
    "homogeneity, completeness, v_measure, adjusted_rand, adjusted_mutual_info = evaluation_metrics(y, label1)\n",
    "print(\". homogeneity: {:0.2f}, completeness: {:0.2f}, v_measure: {:0.2f}, adjusted_rand: {:0.2f}, adjusted_mutual_info: {:0.2f}\"\\\n",
    "      .format(homogeneity, completeness, v_measure, adjusted_rand, adjusted_mutual_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrovsrv32kjF"
   },
   "outputs": [],
   "source": [
    "# Problem 2(a)-ii \n",
    "# Apply PCA with X'(# of features = 30)\n",
    "# Run your K-means implementation 10 times on X′\n",
    "# each with a different random initializations of the cluster centroids in Step 1\n",
    "# Select the K-means results (out of the 10 runs) with the smallest objective value, and report the five evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PFtu8D9Z2kk8",
    "outputId": "1f279d77-d908-4529-d3b0-65f0d8e230a4"
   },
   "outputs": [],
   "source": [
    "print(\"[Problem 2(a)-ii]\")\n",
    "print(\". Apply PCA with X'(# of features = 30)\")\n",
    "pca = PCA(n_components=30) # Apply PCA with X'(# of features = 30)\n",
    "pca_X = pca.fit_transform(X)\n",
    "\n",
    "lowest_objective = 1e9\n",
    "for _ in range(10):  #Run your K-means implementation 10 times on X′\n",
    "    label, objective, centroids = kmeans(pca_X, n_digits, init=\"ForgySeedMethod\")\n",
    "    if (objective < lowest_objective): # Select the K-means results (out of the 10 runs) with the smallest objective value,\n",
    "        lowest_objective = objective\n",
    "        homogeneity, completeness, v_measure, adjusted_rand, adjusted_mutual_info = evaluation_metrics(y, label)\n",
    "        label2 = label\n",
    "\n",
    "#report the five evaluation metrics\n",
    "print(\". Report the five evaluation metrics: \")\n",
    "print(\". homogeneity: {:0.2f}, completeness: {:0.2f}, v_measure: {:0.2f}, adjusted_rand: {:0.2f}, adjusted_mutual_info: {:0.2f}\"\\\n",
    "      .format(homogeneity, completeness, v_measure, adjusted_rand, adjusted_mutual_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "n8KoQnlDrJFw"
   },
   "outputs": [],
   "source": [
    "# TODO: Hungarian algorithm\n",
    "# (b)Bipartite Graph Matching using the Hungarian Algorithm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def mapping_correct_label(label, y, prt=True):\n",
    "    confmat = confusion_matrix(label, y)\n",
    "    #print(\"Confusion matrix: \\n\",  confmat)\n",
    "    matrix = confmat.max() - confmat # Cost is 0 for max value\n",
    "    #print(\"Cost matrix: \\n\", matrix)\n",
    "\n",
    "    m = Munkres()\n",
    "    indexes = m.compute(matrix)\n",
    "    if prt==True:\n",
    "        print(\"Achieved assignment(mapping): \\n\",indexes)\n",
    "\n",
    "    label_mapped = np.zeros(shape=label.shape, dtype=int)\n",
    "    for map in indexes:\n",
    "        label_mapped = label_mapped + np.where(label==map[0], map[1], 0)\n",
    "    #print(\"Accuracy score: \", accuracy_score(y, label_mapped))\n",
    "    return  accuracy_score(y, label_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27l5FF-oIr0G"
   },
   "outputs": [],
   "source": [
    "print(\"[Problem 2(b)-ii]\")\n",
    "print(\"[Label from 2.1.1]\")\n",
    "accuracy = mapping_correct_label(label1, y)\n",
    "confmat = confusion_matrix(label1, y)\n",
    "print(\"Confusion matrix: \\n\",  confmat)\n",
    "print(\"Accuracy score: \", accuracy)\n",
    "\n",
    "print(\"\\n[Label from 2.1.2]\")\n",
    "accuracy = mapping_correct_label(label2, y)\n",
    "confmat = confusion_matrix(label2, y)\n",
    "print(\"Confusion matrix: \\n\",  confmat)\n",
    "print(\"Accuracy score: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ua3y6xQI3TX_",
    "outputId": "11c7c550-8bd0-4cbb-cccc-0df304e758fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 2(c)-i: Implement spectral clustering\n"
     ]
    }
   ],
   "source": [
    "# TODO: Spectral clustering\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "def spectral_clustering(X, k_value=20, N_clusters=10):\n",
    "    \"\"\"\n",
    "    kNN = NearestNeighbors(n_neighbors=500, algorithm='kd_tree', metric='euclidean')\n",
    "    X = kNN.fit(X).kneighbors_graph(mode='distance').toarray()\n",
    "    \"\"\"\n",
    "    # Distance Matrix (Disimilarity)\n",
    "    H = cdist(X, X ,'euclidean')\n",
    "  \n",
    "    #Matrix Afinity E\n",
    "    n=H.shape[0]\n",
    "    sigma = (1/(n*(n-1)))*np.sqrt(H).sum() \n",
    "    E = np.exp(-1*H/(sigma*sigma))\n",
    "\n",
    "  # diagonal matrix D: diagonal entry equals to the degree of the corresponding data point\n",
    "    D = np.zeros(shape=E.shape, dtype=float)\n",
    "    for i in range(X.shape[0]):\n",
    "        D[i][i] = E[i,:].sum()\n",
    "  \n",
    "  # L = I − D−1/2*E*D−1/2 Normalized Lapacian\n",
    "    D_ = np.zeros(shape=D.shape, dtype=float)\n",
    "    for i in range(D.shape[0]):\n",
    "        D_[i][i] = np.reciprocal(np.sqrt(D[i][i]))\n",
    "    I = np.identity(X.shape[0], dtype=float)\n",
    "    L = I-np.matmul(np.matmul(D_, E),D_)\n",
    "  \n",
    "  # eigenvalue decomposition to L\n",
    "    vals, vecs = eigsh(L, which='SM', k=k_value)\n",
    "    V = vecs[:,1:] # remove first column\n",
    "  \n",
    "    best_score = 0\n",
    "    for _ in range(3):  #Run your K-means implementation 10 times on X′\n",
    "        # K-means algorithm\n",
    "        kmeans = KMeans(init=\"k-means++\", n_clusters=N_clusters, n_init=N_clusters).fit(V)\n",
    "        labels = kmeans.labels_\n",
    "        centroids = kmeans.cluster_centers_\n",
    "        #print(np.unique(labels))\n",
    "        score = mapping_correct_label(labels, y, prt=False)\n",
    "        if (score > best_score):\n",
    "            best_score = score\n",
    "            label_final = labels\n",
    "            centroids_final = centroids\n",
    "\n",
    "    return label_final, centroids_final\n",
    "  \n",
    "print(\"Problem 2(c)-i: Implement spectral clustering\")\n",
    "pca = PCA(n_components=30) # Apply PCA with X'(# of features = 30)\n",
    "pca_X = pca.fit_transform(X)\n",
    "labels_SC, centroids_SC = spectral_clustering(pca_X, k_value=20, N_clusters=10)\n",
    "accuracy = mapping_correct_label(labels_SC, y)\n",
    "print(\"Accuracy score: \", accuracy)\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y, labels_SC))\n",
    "print(\"Report the five evaluation metrics: \")\n",
    "homogeneity, completeness, v_measure, adjusted_rand, adjusted_mutual_info = evaluation_metrics(y, labels_SC)\n",
    "print(\". homogeneity: {:0.2f}, completeness: {:0.2f}, v_measure: {:0.2f}, adjusted_rand: {:0.2f}, adjusted_mutual_info: {:0.2f}\"\\\n",
    "      .format(homogeneity, completeness, v_measure, adjusted_rand, adjusted_mutual_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q38rCCCBKMSQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwP_wTm2KMVl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s05SVtWRKMZl"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "# k: k neighbors\n",
    "# N_clusters: # of centroids\n",
    "def kNN_clustering(X, y, init=\"kMean\", k=3, N_clusters=100):\n",
    "    if init==\"kMean\":\n",
    "    # K-means + kNN\n",
    "        test = X\n",
    "        #kmeans = KMeans(init=\"k-means++\", n_clusters=N_clusters, n_init=N_clusters).fit(test) # get 100 centroids\n",
    "        label, objective, centroids = kmeans(test, N_clusters, init=\"ForgySeedMethod\")\n",
    "    #centroids = kmeans.cluster_centers_ # trained data for KNN\n",
    "    elif init==\"Random_Selection\":\n",
    "        test = X\n",
    "        idx = np.random.choice(len(test), N_clusters, replace=False)\n",
    "        centroids = test[idx, :]\n",
    "    elif init==\"Spectral_Clustering\":\n",
    "        # Spectral Clustering + kNN\n",
    "        test = X\n",
    "        labels_SC, centroids = spectral_clustering(test, k_value=test.shape[1]+1, N_clusters=N_clusters) # get 100 centroids\n",
    "\n",
    "  # We select the sample closest to each of the obtained 100 cluster centroids C\n",
    "    dist = cdist(test, centroids)\n",
    "    train_y = []\n",
    "    for i in range(N_clusters):\n",
    "        index = np.where(dist[:,i]==np.amin(dist[:,i]))[0][0]\n",
    "        train_x.append(test[index])\n",
    "        train_y.append(y[index])\n",
    "    train_x = np.array(train_x) # Sample closest to cluster\n",
    "    train_y = np.array(train_y).flatten() # label of sample\n",
    "  \n",
    "    # Test: test (69900 data), Train: train (100 cetnroid data)\n",
    "    dist = cdist(test, train_x, 'euclidean')\n",
    "  \n",
    "    pred = []\n",
    "    for i in range(dist.shape[0]):\n",
    "        sorted_index = sorted(range(len(dist[i])), key=lambda k: dist[i][k]) #sort by distance. return array index\n",
    "        sorted_index = sorted_index[0:k] # index of kNN\n",
    "        kNN_labels = train_y[sorted_index] # labels of kNN\n",
    "        #print(kNN_labels)\n",
    "        vote = np.bincount(kNN_labels).argmax() #vote among kNN \n",
    "        #print(vote)\n",
    "        pred.append(vote)\n",
    "\n",
    "    pred = np.array(pred)\n",
    "    return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sX0l2a9hKMdg"
   },
   "outputs": [],
   "source": [
    "k_kNN=[1,3,5]\n",
    "for k_ in k_kNN:\n",
    "    pred = kNN_clustering(pca_X, y, init=\"kMean\",k=k_)\n",
    "    accuracy = mapping_correct_label(pred, y, prt=False)\n",
    "    print(\"Accuracy score for kMean+kNN ({} neighbors): {}\".format(k_,accuracy))\n",
    "for k_ in k_kNN:\n",
    "    pred = kNN_clustering(pca_X, y, init=\"Random_Selection\",k=k_)\n",
    "    accuracy = mapping_correct_label(pred, y, prt=False)\n",
    "    print(\"Accuracy score for Random_Selection+kNN ({} neighbors): {}\".format(k_,accuracy))\n",
    "for k_ in k_kNN:\n",
    "    pred = kNN_clustering(pca_X, y, init=\"Spectral_Clustering\",k=k_)\n",
    "    accuracy = mapping_correct_label(pred, y, prt=False)\n",
    "    print(\"Accuracy score for Spectral_Clustering+kNN ({} neighbors): {}\".format(k_,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEuDmgTW3Tgm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqKG7KE6Jdvi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLqnfMBCLNP0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
